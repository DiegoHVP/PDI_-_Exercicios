<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.16">
<meta name="author" content="Diêgo Henrique Viana Pereira &lt;diego.henrique.706@ufrn.edu.br&gt;">
<title>Processamento digital de imagens</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;-webkit-tap-highlight-color:transparent}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos{border-right:1px solid;opacity:.35;padding-right:.5em}
pre.pygments .lineno{border-right:1px solid;opacity:.35;display:inline-block;margin-right:.75em}
pre.pygments .lineno::before{content:"";margin-right:-.125em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all tr,table.stripes-odd tr:nth-of-type(odd),table.stripes-even tr:nth-of-type(even),table.stripes-hover tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
ol>li p,ul>li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
.gist .file-data>table{border:0;background:#fff;width:100%;margin-bottom:0}
.gist .file-data>table td.line-data{width:99%}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body class="article">
<div id="header">
<h1>Processamento digital de imagens</h1>
<div class="details">
<span id="author" class="author">Diêgo Henrique Viana Pereira &lt;diego.henrique.706@ufrn.edu.br&gt;</span><br>
</div>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_introdução">Introdução</a></li>
<li><a href="#_capitulo_02_manipulando_pixels_em_uma_imagem">1. Capitulo 02 - Manipulando pixels em uma imagem</a>
<ul class="sectlevel2">
<li><a href="#_exercício_regiões">1.1. Exercício <strong><em>Regiões</em></strong></a></li>
<li><a href="#_exercício_troca_de_regiões">1.2. Exercício <strong><em>Troca de regiões</em></strong></a></li>
</ul>
</li>
<li><a href="#_preenchendo_regiões">2. Preenchendo regiões</a>
<ul class="sectlevel2">
<li><a href="#_exercício_labeling_1º_parte">2.1. Exercício <strong><em>labeling</em></strong> (1º Parte)</a></li>
<li><a href="#_exercício_labeling_2º_parte">2.2. Exercício <strong><em>labeling</em></strong> (2º Parte)</a></li>
</ul>
</li>
<li><a href="#_manipulação_de_histogramas">3. Manipulação de histogramas</a>
<ul class="sectlevel2">
<li><a href="#_exercício_equalize">3.1. Exercício <strong><em>Equalize</em></strong></a></li>
<li><a href="#_exercício_motiondetector">3.2. Exercício <strong><em>motiondetector</em></strong></a></li>
</ul>
</li>
<li><a href="#_filtragem_no_domínio_espacial_i">4. Filtragem no domínio espacial I</a>
<ul class="sectlevel2">
<li><a href="#_exercício_laplgauss">4.1. Exercício <strong><em>laplgauss</em></strong></a></li>
</ul>
</li>
<li><a href="#_filtragem_no_domínio_espacial_ii">5. Filtragem no domínio espacial II</a>
<ul class="sectlevel2">
<li><a href="#_exercicio_tiltshift">5.1. Exercicio <strong><em>tiltshift</em></strong></a></li>
<li><a href="#_exercicio_tiltshiftvideo">5.2. Exercicio <strong><em>tiltshiftvideo</em></strong></a></li>
</ul>
</li>
<li><a href="#_filtragem_no_domínio_da_frequência">6. Filtragem no domínio da frequência</a>
<ul class="sectlevel2">
<li><a href="#_exercício_filtro_homomórfico">6.1. Exercício <strong><em>filtro homomórfico</em></strong></a></li>
</ul>
</li>
<li><a href="#_detecção_de_bordas_com_o_algoritmo_de_canny">7. Detecção de bordas com o algoritmo de Canny</a>
<ul class="sectlevel2">
<li><a href="#_exercício_cannypoints">7.1. Exercício <strong><em>cannypoints</em></strong></a></li>
</ul>
</li>
<li><a href="#_quantização_vetorial_com_k_means">8. Quantização vetorial com <em>k-means</em></a>
<ul class="sectlevel2">
<li><a href="#_exercício_kmeans">8.1. Exercício <strong><em>kmeans</em></strong></a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_introdução">Introdução</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Este site se destina a apresentação da solução dos exercícios propostos na disciplina de Processamento Digital de Imagens (DCA0445) disponibilizado pelo Departamento de Engenharia de Computação e Automação da UFRN e ministrado pelo professor Agostinho Brito, cujo curso se encontra disponível em <a href="https://agostinhobritojr.github.io/tutorial/pdi/" class="bare">https://agostinhobritojr.github.io/tutorial/pdi/</a>.</p>
</div>
<div class="paragraph">
<p>Todos os exercícios a seguir foram desenvolvidos em C++, juntamente com a biblioteca OpenCV <a href="https://opencv.org/" class="bare">https://opencv.org/</a>, compilados usando o <em>Makefile</em> disponibilizado no site do curso. Para compilar e executar os códigos precisamos usar os seguintes comandos:
crie uma arquivo com um nome qualquer e adicione o codigo desejado, na mesma pasta crie um outro arquivo chamado CMakeLists.txt e adicione o seguinte codigos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cmake">cmake_minimum_required(VERSION 3.0.0)
project(&lt;nome_do_arquivo_do_codigo&gt; VERSION 0.1.0 LANGUAGES C CXX)

find_package(OpenCV REQUIRED)
include_directories(${OpenCV_INCLUDE_DIRS})

add_executable(&lt;nome_do_arquivo_do_codigo&gt; &lt;nome_do_arquivo_do_codigo&gt;.cpp)
target_link_libraries(&lt;nome_do_arquivo_do_codigo&gt; ${OpenCV_LIBS})</code></pre>
</div>
</div>
<div class="paragraph">
<p>Feito isso, basta executar no terminal:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="bash">$ mkdir build
$ cd build
$ CMakeLists ..
$ make</code></pre>
</div>
</div>
<div class="paragraph">
<p>Assim você tera um executavel do codigo.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_capitulo_02_manipulando_pixels_em_uma_imagem">1. Capitulo 02 - Manipulando pixels em uma imagem</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Neste tópico vemos como abrir e exibir uma imagem, além de acessar e modificar seus pixels, usando as ferramentas acima.</p>
</div>
<div class="sect2">
<h3 id="_exercício_regiões">1.1. Exercício <strong><em>Regiões</em></strong></h3>
<div class="paragraph">
<p>Usando <code>U1/CH2 - Manipulando pixels em uma imagem/negativo/regioes.cpp</code> como referência, foi implementado um algorítmo que recebe uma imagem (passando-a para escala de cinza) e inverte as cores de uma região definida pelas coordenadas de dois pontos.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;opencv2/opencv.hpp&gt;
#include &lt;iostream&gt;

int main() {

    // Carregar a imagem
    cv::Mat img = cv::imread("../imagem.jpg", cv::IMREAD_GRAYSCALE);
    if (img.empty()) {
        std::cout &lt;&lt; "Erro ao carregar a imagem!" &lt;&lt; std::endl;
        return -1;
    }

    // Coordenadas dos pontos P1 e P2
    int x1, y1, x2, y2;
    std::cout &lt;&lt; "Informe os pontos de P1 (x1, y1): ";
    std::cin &gt;&gt; x1 &gt;&gt; y1;
    std::cout &lt;&lt; "Informe os pontos de P2 (x2, y2): ";
    std::cin &gt;&gt; x2 &gt;&gt; y2;

    // trata os limites da imagem
    x1 = std::max(0, std::min(x1, img.cols - 1));
    y1 = std::max(0, std::min(y1, img.rows - 1));
    x2 = std::max(0, std::min(x2, img.cols - 1));
    y2 = std::max(0, std::min(y2, img.rows - 1));
    
    // trata limites invertidos
    if (x1 &gt; x2) {
        int temp = x1;
        x1 = x2;
        x2 = temp;
    }
    if (y1 &gt; y2) {
        int temp = y1;
        y1 = y2;
        y2 = temp;
    }

    // Copia da imagem
    cv::Mat img_negativo = img.clone();

    // Aplicar o negativo
    for (int i = x1; i &lt; x2; i++) {
        for (int j = y1; j &lt; y2; j++) {
           img_negativo.at&lt;uchar&gt;(i, j) = 255 - img_negativo.at&lt;uchar&gt;(i, j);
        }
    }
    
    
    // Exibir a imagem
    cv::imshow("Imagem com Negativo na Região", img_negativo);
    cv::waitKey(0);

    return 0;
}</code></pre>
</div>
</div>
<div id="img-regioes" class="imageblock">
<div class="content">
<img src="imagens/figura1.png" alt="Resultado">
</div>
<div class="title">Figure 1. Resultado da execução do programa regions.cpp</div>
</div>
</div>
<div class="sect2">
<h3 id="_exercício_troca_de_regiões">1.2. Exercício <strong><em>Troca de regiões</em></strong></h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/pixels.cpp como referência, foi implementado um programa que troca as regiões da imagem (convertida em tons de cinza) fornecida. Nesse exemplo foi explorado o uso de uma função disponível no OpenCV para extrair regiões de uma imagem e outra que permite a cópia de uma Matriz <code>Mat</code> em outra.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  //Divide a imagem original em 4 regiões com tamanho (imagem.rows/2, imagem.cols/2)
  Mat imagem = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  Mat q1 = imagem(Rect(0, 0, imagem.rows / 2, imagem.cols / 2));
  Mat q2 = imagem(Rect(0, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2));
  Mat q3 = imagem(Rect(imagem.rows / 2, 0, imagem.rows / 2, imagem.cols / 2));
  Mat q4 = imagem(Rect(imagem.rows / 2, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2));

  namedWindow("imagem_original", WINDOW_AUTOSIZE);
  imshow("imagem_original", imagem);
  waitKey();

  //Cria matrix com mesmo tamanho da imagem original
  Mat imagemtrocada(imagem.rows, imagem.cols, imagem.type());

  //Copia os quadrantes dentro das novas regiões
  q4.copyTo(imagemtrocada(Rect(0, 0, imagem.rows / 2, imagem.cols / 2)));
  q3.copyTo(imagemtrocada(Rect(0, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2)));
  q2.copyTo(imagemtrocada(Rect(imagem.rows / 2, 0, imagem.rows / 2, imagem.cols / 2)));
  q1.copyTo(imagemtrocada(Rect(imagem.rows / 2, imagem.cols / 2, imagem.rows / 2, imagem.cols / 2)));

  namedWindow("imagem_trocada", WINDOW_AUTOSIZE);
  imshow("imagem_trocada", imagemtrocada);
  waitKey();
  return 0;
}</code></pre>
</div>
</div>
<div id="img-trocaregioes" class="imageblock">
<div class="content">
<img src="imagens/figura2.png" alt="Resultado">
</div>
<div class="title">Figure 2. Resultado da execução do programa trocaregioes.cpp</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_preenchendo_regiões">2. Preenchendo regiões</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nessa seção aprendemos sobre o algorítmo <em>floodfill</em>, usado para preencher regiões, e o aplicamos em um programa que contabiliza as bolhas e as bolas brancas em uma imagem de fundo preto.</p>
</div>
<div class="sect2">
<h3 id="_exercício_labeling_1º_parte">2.1. Exercício <strong><em>labeling</em></strong> (1º Parte)</h3>
<div class="paragraph">
<p>Esse problema ocorre porque a cor de cada pixel da imagem é composta por 8 bits (ou 256 valores), portanto não dá para atribuir uma valor maior que 255 aos pixels da matriz. Para resolver isso, poderíamos atribuir uma cor para cada tipo de objeto (bolhas e bolas) em vez de uma cor diferente para cada objeto.</p>
</div>
</div>
<div class="sect2">
<h3 id="_exercício_labeling_2º_parte">2.2. Exercício <strong><em>labeling</em></strong> (2º Parte)</h3>
<div class="paragraph">
<p>A partir do labeling.cpp, o algorítmo de contagem foi aprimorado, levando em consideração objetos com mais de um buraco e excluindo as bolhas que tocam a borda da contagem. Abaixo podemos ver o código e o resultado de sua execução:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;stack&gt;

using namespace cv;
using namespace std;

struct posicao
{
  int x;
  int y;
};

Mat imagem;

void floodfill(int x, int y, int cor_atual, int nova_cor)
{
  stack&lt;posicao&gt; pintar;

  posicao inicial;
  inicial.x = x;
  inicial.y = y;

  pintar.push(inicial);

  while (!pintar.empty())
  {
    posicao posicao_atual = pintar.top();
    pintar.pop();
    imagem.at&lt;uchar&gt;(posicao_atual.x, posicao_atual.y) = nova_cor;

    //Verifica os 4- vizinhos do ponto
    if (posicao_atual.x - 1 &gt;= 0 &amp;&amp; imagem.at&lt;uchar&gt;(posicao_atual.x - 1, posicao_atual.y) == cor_atual)
    {
      pintar.push({posicao_atual.x - 1, posicao_atual.y});
    }
    if (posicao_atual.y - 1 &gt;= 0 &amp;&amp; imagem.at&lt;uchar&gt;(posicao_atual.x, posicao_atual.y - 1) == cor_atual)
    {
      pintar.push({posicao_atual.x, posicao_atual.y - 1});
    }
    if (posicao_atual.x + 1 &lt; imagem.rows &amp;&amp; imagem.at&lt;uchar&gt;(posicao_atual.x + 1, posicao_atual.y) == cor_atual)
    {
      pintar.push({posicao_atual.x + 1, posicao_atual.y});
    }
    if (posicao_atual.y + 1 &lt; imagem.cols &amp;&amp; imagem.at&lt;uchar&gt;(posicao_atual.x, posicao_atual.y + 1) == cor_atual)
    {
      pintar.push({posicao_atual.x, posicao_atual.y + 1});
    }
  }
}

int main(int, char **)
{

  int cor = 1;
  int bolhas = 0, bolas = 0;

  imagem = imread("bolhas.png", CV_LOAD_IMAGE_GRAYSCALE);
  if (!imagem.data)
    cout &lt;&lt; "nao abriu bolhas.png" &lt;&lt; endl;

  imshow("Imagem original", imagem);
  waitKey();

  //Percorrendo bordas superiores e inferiores e eliminando bolhas juntas delas
  for (int y = 0; y &lt; imagem.cols; y++)
  {
    if (imagem.at&lt;uchar&gt;(0, y) == 255)
    {
      floodfill(0, y, 255, 0);
    }
    if (imagem.at&lt;uchar&gt;(imagem.rows - 1, y) == 255)
    {
      floodfill(imagem.rows - 1, y, 255, 0);
    }
  }

  //Percorrendo bordas laterais e eliminando bolhas juntas delas
  for (int x = 0; x &lt; imagem.rows; x++)
  {
    if (imagem.at&lt;uchar&gt;(x, 0) == 255)
    {
      floodfill(x, 0, 255, 0);
    }
    if (imagem.at&lt;uchar&gt;(x, imagem.cols - 1) == 255)
    {
      floodfill(x, imagem.cols - 1, 255, 0);
    }
  }

  imshow("Removendo bolhas das bordas", imagem);
  waitKey();

  //Colore as bolhas e bolas de cinza
  for (int x = 0; x &lt; imagem.rows; x++)
  {
    for (int y = 0; y &lt; imagem.cols; y++)
    {
      if (imagem.at&lt;uchar&gt;(x, y) == 255)
      {
        floodfill(x, y, 255, cor);
        cor++;
      }
    }
  }

  imshow("Destacando bolhas e bolas", imagem);
  waitKey();

  //Pinta o lado de fora do quadro de branco, assim lado interno das bolhas permanecerá preto, facilitando sua localização
  floodfill(0, 0, 0, 255);

  //Procura bolhas (bolas pretas dentro de bolhas de outra cor)
  for (int x = 0; x &lt; imagem.rows; x++)
  {
    for (int y = 0; y &lt; imagem.cols; y++)
    {
      if (imagem.at&lt;uchar&gt;(x, y) == 0)
      {
        //Verifica se a bola preta está dentro de outro objeto (não branco)
        if (imagem.at&lt;uchar&gt;(x, y - 1) != 255)
        {
          //Caso positivo, incrementa o número de bolhas e pinta de branco
          bolhas++;
          floodfill(x, y, 0, 255);
          floodfill(x, y - 1, imagem.at&lt;uchar&gt;(x, y - 1), 255);
        }
        else
        {
          //Se não, apenas pinta de branco, tornando-o parte do fundo (o que pode acontece caso uma bolha tenha 2 buracos)
          floodfill(x, y, 0, 255);
        }
      }
    }
  }

  cout &lt;&lt; "Bolhas: " &lt;&lt; bolhas &lt;&lt; endl;
  imshow("Bolas", imagem);
  waitKey();

  //Com todas as bolhas retiradas, procuram-se as bolas
  for (int x = 0; x &lt; imagem.rows; x++)
  {
    for (int y = 0; y &lt; imagem.cols; y++)
    {
      //Se a cor do ponto for diferente da do fundo, já que todas as bolhas foram retiradas, só pode ser um bola
      if (imagem.at&lt;uchar&gt;(x, y) != 255)
      {
        bolas++;
        floodfill(x, y, imagem.at&lt;uchar&gt;(x, y), 255);
      }
    }
  }

  cout &lt;&lt; "Bolas: " &lt;&lt; bolas &lt;&lt; endl;
  imshow("Resultado final", imagem);
  waitKey();

  return 0;
}</code></pre>
</div>
</div>
<div id="img-labeling" class="imageblock">
<div class="content">
<img src="imagens/figura32.png" alt="Resultado">
</div>
<div class="title">Figure 3. Etapas da execução e resultado do programa labeling.cpp</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_manipulação_de_histogramas">3. Manipulação de histogramas</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Essa seção abordou a manipulação de histogramas e a captura de videos no OpenCV.</p>
</div>
<div class="sect2">
<h3 id="_exercício_equalize">3.1. Exercício <strong><em>Equalize</em></strong></h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/histogram.cpp como referência, implementamos um código que realiza a equalização dos quadros (convertidos para tons de cinza) que compõem o vídeo. Abaixo, temos o código e em seguida a comparação entre uma imagem sem tratamento e a equalizada.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  int des_altura_hist = 64;
  int des_largura_hist = 256;
  int tam_hist = 256;
  float range[] = {0, 256};
  const float *histrange = {range};

  VideoCapture video;
  Mat quadro, histograma, histograma_eq, quadro_gray;

  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout &lt;&lt; "Video não está aberto" &lt;&lt; endl;
    return -1;
  }

  while (true)
  {
    video &gt;&gt; quadro;

    //Converte quadro para tons de cinza
    cvtColor(quadro, quadro_gray, CV_BGR2GRAY);
    calcHist(&amp;quadro_gray, 1, 0, Mat(), histograma, 1, &amp;tam_hist, &amp;histrange);

    int novos_tons[des_largura_hist] = {0};

    //Este loop percorre o histograma calculando o histrograma acumulado, calculando e
    //armazenando no vetor novos_tons os novos tons que os valores antigos devem assumir:
    //novos_tons[tom_antigo] = tom_novo
    int soma = 0;
    for (int i = 0; i &lt; tam_hist; i++)
    {
      soma += histograma.at&lt;float&gt;(i);
      novos_tons[i] = soma * 255.0 / quadro_gray.total();
    }

    Mat resultado(quadro_gray.rows, quadro_gray.cols, CV_8U);

    //Aplica os novos tons no frame, equalizando a imagem
    for (int i = 0; i &lt; quadro_gray.rows; i++)
    {
      for (int j = 0; j &lt; quadro_gray.cols; j++)
      {
        resultado.at&lt;uchar&gt;(i, j) = novos_tons[quadro_gray.at&lt;uchar&gt;(i, j)];
      }
    }

    //Calcula histograma equalizado
    calcHist(&amp;resultado, 1, 0, Mat(), histograma_eq, 1, &amp;tam_hist, &amp;histrange);

    //Cria matriz para o desenho do histograma
    Mat des_hist_original(des_altura_hist, des_largura_hist, CV_8U, Scalar(0));
    Mat des_hist_equalizado(des_altura_hist, des_largura_hist, CV_8U, Scalar(0));

    //Normaliza os histogramas de 0 a 64
    normalize(histograma, histograma, 0, des_hist_original.rows, NORM_MINMAX, -1, Mat());
    normalize(histograma_eq, histograma_eq, 0, des_hist_equalizado.rows, NORM_MINMAX, -1, Mat());

    //Desenha os histogramas
    for (int i = 0; i &lt; des_largura_hist; i++)
    {
      line(des_hist_original,
           Point(i, des_altura_hist),
           Point(i, des_altura_hist - cvRound(histograma.at&lt;float&gt;(i))),
           Scalar(255), 1, 8, 0);
      line(des_hist_equalizado,
           Point(i, des_altura_hist),
           Point(i, des_altura_hist - cvRound(histograma_eq.at&lt;float&gt;(i))),
           Scalar(255), 1, 8, 0);
    }

    des_hist_original.copyTo(quadro_gray(Rect(0, 0, des_largura_hist, des_altura_hist)));
    des_hist_equalizado.copyTo(resultado(Rect(0, 0, des_largura_hist, des_altura_hist)));

    imshow("original", quadro_gray);
    imshow("equalizado", resultado);
    if (waitKey(30) == 27)
      break;
  }
}</code></pre>
</div>
</div>
<div id="img-equalize1" class="imageblock">
<div class="content">
<img src="imagens/figura4.png" alt="Resultado">
</div>
<div class="title">Figure 4. Comparação entre a saída inalterada e a equalizada</div>
</div>
<div class="paragraph">
<p>Apesar da equalização evidenciar os detalhes escondidos na imagem original, a imagem ficou distorcida por causa do efeito do falso contorno, uma vez que ao passar pelo processo de equalização, os tons dos pixels se distanciaram.</p>
</div>
</div>
<div class="sect2">
<h3 id="_exercício_motiondetector">3.2. Exercício <strong><em>motiondetector</em></strong></h3>
<div class="paragraph">
<p>Nesse exercício, ainda com base no programa exemplos/histogram.cpp, foi implementado uma algorítmo que detecta movimentos. Isso é feito calculando a diferença relativa entre o histograma atual e o anterior do canal verde da imagem. Caso a diferença ultrapasse um limite, que pode ser definido pelo programador, então uma bola vermelha é desenhada no canto superior direto, indicando movimento.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace std;
using namespace cv;

int main(int argc, char **argv)
{
  int des_altura_hist = 64;
  int des_largura_hist = 256;

  //limite da diferença entre histogramas, servindo como gatilho para
  //detecção
  int limite = 15;

  VideoCapture video;
  Mat frame;

  //É criado vetor para armazenar componentes RGB
  vector&lt;Mat&gt; componentes_rgb;

  //Armazenam histograma do frame passado e do atual
  Mat hist_passado;

  //Intervalo do histograma
  float range[] = {0, 256};
  const float *histRange = {range};
  int tamanho_histograma = 256;

  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout &lt;&lt; "Falha na abertura" &lt;&lt; endl;
    return (-1);
  }

  int largura = video.get(CV_CAP_PROP_FRAME_WIDTH);

  namedWindow("Video", 1);
  while (true)
  {
    Mat histG, histG_norm;
    video &gt;&gt; frame;

    //Separa a imagem colorida em 3 canais
    split(frame, componentes_rgb);

    //Calcula histograma da componente verde
    calcHist(&amp;componentes_rgb[1], 1, 0, Mat(), histG, 1, &amp;tamanho_histograma, &amp;histRange);

    //Cria matriz para o desenho do histograma
    Mat des_hist_atual(des_altura_hist, des_largura_hist, CV_8UC3, Scalar(0, 0, 0));

    //Normaliza o histograma da cor verde de 0 a 64
    normalize(histG, histG_norm, 0, des_hist_atual.rows, NORM_MINMAX, -1, Mat());

    //Calcula erro relativo médio
    if (!hist_passado.empty())
    {
      double erro_verde = 0.0;

      //Compara cada posição do histograma atual como antigo
      for (int i = 0; i &lt; tamanho_histograma; i++)
      {
        if (histG.at&lt;float&gt;(i) != 0)
        {
          erro_verde += abs((histG.at&lt;float&gt;(i) - hist_passado.at&lt;float&gt;(i)) / histG.at&lt;float&gt;(i));
        }
      }

      //Desenha um circulo vermelho caso detecte movimento
      if (erro_verde &gt; limite)
      {
        circle(frame, Point(largura - 20, 20), 10, Scalar(0, 0, 255), CV_FILLED);
      }

      //Desenha os histogramas
      for (int i = 0; i &lt; des_largura_hist; i++)
      {
        line(des_hist_atual,
             Point(i, des_altura_hist),
             Point(i, des_altura_hist - cvRound(histG_norm.at&lt;float&gt;(i))),
             Scalar(255, 255, 255), 1, 8, 0);
      }
    }

    //Copia histograma no frame
    des_hist_atual.copyTo(frame(Rect(0, 0, des_largura_hist, des_altura_hist)));

    imshow("Video", frame);
    if (waitKey(30) == 27)
      break;

    histG.copyTo(hist_passado);
  }

  return 0;
}</code></pre>
</div>
</div>
<div id="img-motiondetection" class="imageblock">
<div class="content">
<img src="imagens/figura5.png" alt="Resultado">
</div>
<div class="title">Figure 5. Resultado do programa motiondetection.cpp</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_filtragem_no_domínio_espacial_i">4. Filtragem no domínio espacial I</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nessa seção aprendemos a usar a função filter2D para a realização da convolução digital entre uma imagem e uma máscara.</p>
</div>
<div class="sect2">
<h3 id="_exercício_laplgauss">4.1. Exercício <strong><em>laplgauss</em></strong></h3>
<div class="paragraph">
<p>Usando o programa exemplos/filtroespacial.cpp como base, adicionamos a opção de aplicar o filtro do laplaciano após aplicar o gaussiano na imagem pressionando a letra <code>f</code>. Para isso, definimos <code>mask</code> como o gaussiano e atribuimos o valor verdadeiro a variável <code>lapgauss</code>. Quando o programa vai aplicar o filtro selecionado, se <code>lapgauss</code> for verdadeiro, o filtro laplaciano é aplicado logo após o gaussiano. Quando outro modo é selecionado, a variável <code>lapgauss</code> assume o valor falso e, consequentemente, apenas o filtro selecionado é aplicado.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace cv;
using namespace std;

void printmask(Mat &amp;m)
{
  for (int i = 0; i &lt; m.size().height; i++)
  {
    for (int j = 0; j &lt; m.size().width; j++)
    {
      cout &lt;&lt; m.at&lt;float&gt;(i, j) &lt;&lt; ",";
    }
    cout &lt;&lt; endl;
  }
}

void menu()
{
  cout &lt;&lt; "\npressione a tecla para ativar o filtro: \n"
          "a - calcular modulo\n"
          "m - media\n"
          "g - gauss\n"
          "v - vertical\n"
          "h - horizontal\n"
          "l - laplaciano\n"
          "esc - sair\n";
}

int main(int argvc, char **argv)
{
  VideoCapture video;
  float media[] = {1, 1, 1,
                   1, 1, 1,
                   1, 1, 1};
  float gauss[] = {1, 2, 1,
                   2, 4, 2,
                   1, 2, 1};
  float horizontal[] = {-1, 0, 1,
                        -2, 0, 2,
                        -1, 0, 1};
  float vertical[] = {-1, -2, -1,
                      0, 0, 0,
                      1, 2, 1};
  float laplacian[] = {0, -1, 0,
                       -1, 4, -1,
                       0, -1, 0};

  Mat cap, frame, frame32f, frameFiltered;
  Mat mask(3, 3, CV_32F), mask1;
  Mat result, result1;
  double width, height, min, max;
  int absolut;
  char key;

  //Variável que indica se o filtro lapgauss está ativado
  bool lapgauss = false;

  video.open("video6.mp4");
  if (!video.isOpened())
    return -1;
  width = video.get(CV_CAP_PROP_FRAME_WIDTH);
  height = video.get(CV_CAP_PROP_FRAME_HEIGHT);
  std::cout &lt;&lt; "largura=" &lt;&lt; width &lt;&lt; "\n";
  ;
  std::cout &lt;&lt; "altura =" &lt;&lt; height &lt;&lt; "\n";
  ;

  namedWindow("filtroespacial", 1);

  mask = Mat(3, 3, CV_32F, media);
  scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
  swap(mask, mask1);
  absolut = 1; // calcs abs of the image

  menu();
  for (;;)
  {
    video &gt;&gt; cap;
    cvtColor(cap, frame, CV_BGR2GRAY);
    flip(frame, frame, 1);
    imshow("original", frame);
    frame.convertTo(frame32f, CV_32F);

    //Se o filtro lapgauss estiver ativado, o programa aplica a máscara do laplaciano após aplicar
    //a máscara gaussiana (que foi definida abaixo). Caso contrário, apenas aplica a máscara selecionada.
    if (lapgauss)
    {
      Mat frameFilteredTemp, mask2(3, 3, CV_32F, laplacian);
      filter2D(frame32f, frameFilteredTemp, frame32f.depth(), mask, Point(1, 1), 0);
      filter2D(frameFilteredTemp, frameFiltered, frameFilteredTemp.depth(), mask2, Point(1, 1), 0);
    }
    else
    {
      filter2D(frame32f, frameFiltered, frame32f.depth(), mask, Point(1, 1), 0);
    }

    if (absolut)
    {
      frameFiltered = abs(frameFiltered);
    }
    frameFiltered.convertTo(result, CV_8U);

    imshow("filtroespacial", result);
    key = (char)waitKey(30);
    if (key == 27)
      break; // esc pressed!

    switch (key)
    {
    case 'a':
      menu();
      absolut = !absolut;
      lapgauss = false;
      break;
    case 'm':
      menu();
      mask = Mat(3, 3, CV_32F, media);
      scaleAdd(mask, 1 / 9.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = false;
      break;
    case 'g':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = false;
      break;
    case 'h':
      menu();
      mask = Mat(3, 3, CV_32F, horizontal);
      printmask(mask);
      lapgauss = false;
      break;
    case 'v':
      menu();
      mask = Mat(3, 3, CV_32F, vertical);
      printmask(mask);
      lapgauss = false;
      break;
    case 'l':
      menu();
      mask = Mat(3, 3, CV_32F, laplacian);
      printmask(mask);
      lapgauss = false;
      break;
    //Adiciona o filtro laplgauss ao programa
    case 'f':
      menu();
      mask = Mat(3, 3, CV_32F, gauss);
      scaleAdd(mask, 1 / 16.0, Mat::zeros(3, 3, CV_32F), mask1);
      mask = mask1;
      printmask(mask);
      lapgauss = true;
      break;
    default:
      break;
    }
  }
  return 0;
}</code></pre>
</div>
</div>
<div id="img-lapgauss" class="imageblock">
<div class="content">
<img src="imagens/figura6.png" alt="Resultado">
</div>
<div class="title">Figure 6. Comparação entre o laplaciano de uma imagem (acima) e o laplaciano do gaussiano (abaixo)</div>
</div>
<div class="paragraph">
<p>Podemos ver que depois de aplicar o laplaciano do gaussiano as bordas estão menos evidentes. Isso acontece porque ao aplicar o filtro gaussiano, borramos a imagem deixando as bordas mais suaves. Como o laplaciano evidencia as bordas, se elas estiverem borradas, essas mudanças de tonalidade serão menos destacadas.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_filtragem_no_domínio_espacial_ii">5. Filtragem no domínio espacial II</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nesta seção aprendemos sobre a execução do efeito <em>tilt-shift</em> usando técnicas de processamento digital de imagens. Também foram apresentados funções para a soma e multiplicação de matrizes.</p>
</div>
<div class="sect2">
<h3 id="_exercicio_tiltshift">5.1. Exercicio <strong><em>tiltshift</em></strong></h3>
<div class="paragraph">
<p>Utilizando o programa exemplos/addweighted.cpp como referência, implementamos um programa para a realização do <em>tilt-shift</em> em uma imagem colorida cujo centro, região de decaimento e posição vertical do efeito podem ser alterados por meio de <em>sliders</em>. Para a realização desse efeito, foram criadas duas matrizes cujos valores do eixo x foram dados pela seguinte equação:</p>
</div>
<div class="paragraph">
<p>\$f(x) = -0.5 * (tanh((x - centro + l1) / d) - tanh((x - centro + l2) / d)\$</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Declarar pelo menos uma das váriáveis usadas dentro do \$tanh()\$ como <code>float</code> para que o argumento não seja arredondado.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Em que <code>centro</code> indica o centro da região em foco, <code>l1</code> e <code>l2</code> os limites dessa região e <code>d</code> o quão suave será a transição entre a imagem focada e a borrada.</p>
</div>
<div class="paragraph">
<p>A matriz resultante desse cálculo é usada para ponderar a imagem sem efeito, e sua inversa \$1-f(x)\$ para ponderar a imagem borrada. Em seguida, ambas são somadas, criando o efeito do <em>tilt-shift</em>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace cv;
using namespace std;

float l1 = -100, l2 = 50, d = 6, centro = 100;

int matriz_media_tam = 7;
int altura, largura;

int slider_altura = 0;
int slider_altura_max = 100;

int slider_decaimento = 0;
int slider_decaimento_max = 100;

int slider_deslocamento = 0;
int slider_deslocamento_max = 100;

Mat imagem, imagem_borrada;

char TrackbarName[50];

void aplicar_Efeito();

void on_trackbar_deslocamento(int, void *)
{
  //O centro é definido pela posição do slider, de forma que
  //0 - topo imagem e 100 -&gt; fundo imagem
  centro = slider_deslocamento * altura / 100;

  aplicar_Efeito();
}

void on_trackbar_altura(int, void *)
{
  //O slider da altura define a distância de l1 e l2 do centro do tilt-shift
  int alt = altura * slider_altura / 100;
  l1 = -alt / 2;
  l2 = alt / 2;

  aplicar_Efeito();
}

void on_trackbar_decaimento(int, void *)
{
  d = slider_decaimento;

  aplicar_Efeito();
}

void aplicar_Efeito()
{
  Mat ponderada(altura, largura, CV_32FC3);
  Mat ponderada_negativa(altura, largura, CV_32FC3);

  cout &lt;&lt; "centro: " &lt;&lt; centro &lt;&lt;
          ", l1: " &lt;&lt; l1 &lt;&lt;
          ", l2: " &lt;&lt; l2 &lt;&lt;
          ", decaimento: " &lt;&lt; d &lt;&lt; endl;

  for (int i = 0; i &lt; altura; i++)
  {
    float fx = 0.0;
    //Como a função não é definida para d = 0, caso isso ocorra, é atribuido um valor
    //pequeno para d (d=0.01), o que deixa a transição entre 0 e 1 quase abrupta
    if (d != 0)
    {
      //função utilizada para ponderar as imagens
      fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
    }
    else{
      fx = -0.5 * (tanh((i - centro + l1) / 0.01) - tanh((i - centro + l2) / 0.01));
    }

    //O tilt shift é aplicado em cada camada da imagem RGB
    for (int j = 0; j &lt; largura; j++)
    {
      ponderada.at&lt;Vec3f&gt;(i, j)[0] = fx;
      ponderada.at&lt;Vec3f&gt;(i, j)[1] = fx;
      ponderada.at&lt;Vec3f&gt;(i, j)[2] = fx;
      ponderada_negativa.at&lt;Vec3f&gt;(i, j)[0] = 1.0 - fx;
      ponderada_negativa.at&lt;Vec3f&gt;(i, j)[1] = 1.0 - fx;
      ponderada_negativa.at&lt;Vec3f&gt;(i, j)[2] = 1.0 - fx;
    }
  }

  Mat resultado, res1, res2;

  //Cada imagem é multiplicada por sua respectiva matriz ponderada
  multiply(imagem, ponderada, res1);
  multiply(imagem_borrada, ponderada_negativa, res2);

  //As matrizes ponderadas são somadas
  addWeighted(res1, 1, res2, 1, 0, resultado);

  resultado.convertTo(resultado, CV_8UC3);

  imshow("tiltshift", resultado);
}

int main(int argvc, char **argv)
{
  //A másca de média, para borramento, é criada
  float media[matriz_media_tam * matriz_media_tam];
  for (int i = 0; i &lt; matriz_media_tam; i++)
  {
    for (int j = 0; j &lt; matriz_media_tam; j++)
    {
      media[i * matriz_media_tam + j] = 1.0 / (matriz_media_tam * matriz_media_tam);
    }
  }
  Mat masc_media(matriz_media_tam, matriz_media_tam, CV_32F, media);

  vector&lt;Mat&gt; canais;

  imagem = imread(argv[1]);
  imagem.convertTo(imagem, CV_32FC3);

  //O filtro do borramento é aplicado em cada canal separadamente
  split(imagem, canais);

  filter2D(canais[0], canais[0], canais[0].depth(), masc_media, Point(3, 3), 0);
  filter2D(canais[1], canais[1], canais[1].depth(), masc_media, Point(3, 3), 0);
  filter2D(canais[2], canais[2], canais[2].depth(), masc_media, Point(3, 3), 0);

  merge(canais, imagem_borrada);

  largura = imagem.cols;
  altura = imagem.rows;

  namedWindow("tiltshift", 1);

  //Criando os sliders
  sprintf(TrackbarName, "Altura x %d", slider_altura_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &amp;slider_altura,
                 slider_altura_max,
                 on_trackbar_altura);
  on_trackbar_altura(slider_altura, 0);

  sprintf(TrackbarName, "Decaimento x %d", slider_decaimento_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &amp;slider_decaimento,
                 slider_decaimento_max,
                 on_trackbar_decaimento);
  on_trackbar_decaimento(slider_decaimento, 0);

  sprintf(TrackbarName, "Deslocamento x %d", slider_deslocamento_max);
  createTrackbar(TrackbarName, "tiltshift",
                 &amp;slider_deslocamento,
                 slider_deslocamento_max,
                 on_trackbar_deslocamento);
  on_trackbar_deslocamento(slider_deslocamento, 0);

  aplicar_Efeito();

  waitKey(0);
  return 0;
}</code></pre>
</div>
</div>
<div id="img-tiltshift" class="imageblock">
<div class="content">
<img src="imagens/figura71.png" alt="Resultado">
</div>
<div class="title">Figure 7. Comparação entre imagem sem (acima) e com (abaixo) o efeito do tilt-shift</div>
</div>
</div>
<div class="sect2">
<h3 id="_exercicio_tiltshiftvideo">5.2. Exercicio <strong><em>tiltshiftvideo</em></strong></h3>
<div class="paragraph">
<p>Ainda usando exemplos/addweighted.cpp como base, foi criado um programa que aplica o efeito de <em>tilt-shift</em> e <em>stop motion</em> em um vídeo colorido. Para isso, além de efetuar os mesmos procedimentos do exercício anterior para o <em>tilt-shift</em>, foi colocado um laço que descarta <code>aceleracao</code> frames do video antes de processar um frame, criando o efeito de <em>stop motion</em>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

using namespace cv;
using namespace std;

int matriz_media_tam = 7;

int main(int argvc, char **argv)
{
  VideoCapture video;
  video.open(argv[1]);
  if (!video.isOpened())
  {
    cout &lt;&lt; "Erro ao abrir video" &lt;&lt; endl;
    return -1;
  }

  int largura = video.get(CV_CAP_PROP_FRAME_WIDTH);
  int altura = video.get(CV_CAP_PROP_FRAME_HEIGHT);

  //Inicializa e preenche a máscara de média
  float media[matriz_media_tam * matriz_media_tam];
  for (int i = 0; i &lt; matriz_media_tam; i++)
  {
    for (int j = 0; j &lt; matriz_media_tam; j++)
    {
      media[i * matriz_media_tam + j] = 1.0 / (matriz_media_tam * matriz_media_tam);
    }
  }

  Mat masc_media(matriz_media_tam, matriz_media_tam, CV_32F, media);

  //Inicializa mascaras do ponderamento
  Mat ponderada(altura, largura, CV_32FC3);
  Mat ponderada_negativa(altura, largura, CV_32FC3);

  int centro = 6*altura / 10, l1 = -70, l2 = 70, aceleracao = 10;
  float d = 30;

  cout &lt;&lt; "centro: " &lt;&lt; centro &lt;&lt;
          ", l1: " &lt;&lt; l1 &lt;&lt;
          ", l2: " &lt;&lt; l2 &lt;&lt;
          ", decaimento: " &lt;&lt; d &lt;&lt;
          ", aceleração " &lt;&lt; aceleracao &lt;&lt; endl;

  for (int i = 0; i &lt; altura; i++)
  {
    //Eliminando caso de divisão por 0
    float fx = 0.0;
    if (d != 0)
    {
      //Formula de ponderação
      fx = -0.5 * (tanh((i - centro + l1) / d) - tanh((i - centro + l2) / d));
    }

    //Criação das matrizes de ponderamento
    for (int j = 0; j &lt; largura; j++)
    {
      ponderada.at&lt;Vec3f&gt;(i, j)[0] = fx;
      ponderada.at&lt;Vec3f&gt;(i, j)[1] = fx;
      ponderada.at&lt;Vec3f&gt;(i, j)[2] = fx;
      ponderada_negativa.at&lt;Vec3f&gt;(i, j)[0] = 1.0 - fx;
      ponderada_negativa.at&lt;Vec3f&gt;(i, j)[1] = 1.0 - fx;
      ponderada_negativa.at&lt;Vec3f&gt;(i, j)[2] = 1.0 - fx;
    }
  }

  Mat imagem, imagem_borrada;

  while (true)
  {
    //Descarta aceleracao quadros
    for (int i = 0; i &lt; aceleracao; i++)
    {
      video &gt;&gt; imagem;
    }

    imagem.convertTo(imagem, CV_32FC3);

    //Separa a imagem nos 3 canais, aplica o efeito do borramento e as junta em seguida
    vector&lt;Mat&gt; canais;
    split(imagem, canais);

    filter2D(canais[0], canais[0], canais[0].depth(), masc_media, Point(3, 3), 0);
    filter2D(canais[1], canais[1], canais[1].depth(), masc_media, Point(3, 3), 0);
    filter2D(canais[2], canais[2], canais[2].depth(), masc_media, Point(3, 3), 0);

    merge(canais, imagem_borrada);

    Mat resultado, res1, res2;

    //Multiplica matrizes pelo respectivo ponderamento
    multiply(imagem, ponderada, res1);
    multiply(imagem_borrada, ponderada_negativa, res2);

    //Soma das matrizes
    addWeighted(res1, 1, res2, 1, 0, resultado);

    resultado.convertTo(resultado, CV_8UC3);

    imshow("tiltshift", resultado);

    //Tempo para mostrar cada quadro foi aumentado para melhorar a
    //visualização do stop motion
    if (waitKey(50) == 27)
      break;
  }

  return 0;
}</code></pre>
</div>
</div>
<div id="img-videotiltshift" class="imageblock">
<div class="content">
<img src="imagens/figura8.png" alt="Resultado">
</div>
<div class="title">Figure 8. Aplicação do tilt-shift e do stop motion em um video</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_filtragem_no_domínio_da_frequência">6. Filtragem no domínio da frequência</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nessa seção aprendemos a passar imagens do domínio espacial para o domínio da frequência (e vice-versa) utilizando a Transformada discreta de Fourier e como podemos usar filtros nesse domínio.</p>
</div>
<div class="sect2">
<h3 id="_exercício_filtro_homomórfico">6.1. Exercício <strong><em>filtro homomórfico</em></strong></h3>
<div class="paragraph">
<p>Usando o programa exemplos/dft.cpp como base, implementamos o filtro homomórfico \$H(u, v)\$ que tem o objetivo de corrigir a iluminação de uma imagem em tons de cinza. Ele foi construído usando a fórmula abaixo:</p>
</div>
<div class="paragraph">
<p>\$H(u, v) = (\gamma_H - \gamma_L)(1 - \exp{-c({D(u, v)^{2}}/D_{0}^2)}) + \gamma_L\$</p>
</div>
<div class="paragraph">
<p>Em que \$\gamma_L, \gamma_H, D_0\$ e \$c\$ são as constantes que definem o comportamento do filtro em função da distância do seu centro \$D(u, v)\$.</p>
</div>
<div id="img-filtrohomomorfico" class="imageblock">
<div class="content">
<img src="imagens/figura91.png" alt="Resultado">
</div>
<div class="title">Figure 9. Filtro homomórfico gerado com parâmetros usados no programa abaixo.</div>
</div>
<div class="paragraph">
<p>Para aplicá-lo, primeiramente redimensionamos a imagem para que sua altura e largura sejam potência de 2 e preenchemos o espaço extra com zeros (<em>padding</em>) o que possibilita o uso da FFT sem afetar a imagem. Em seguida, efetuamos a operação de <code>log</code> na imagem (tanto na parte real como complexa) somada em um para evitar o cálculo de \$log(0)\$. Então realizamos a Tranformada de Fourier, deslocamos o espectro, multiplicamos o filtro com o espectro e então fazemos a operação inversa. Por fim, efetuamos o <code>exp</code> na imagem e a normalizamos para exibição.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include &lt;cmath&gt;
#include &lt;opencv2/opencv.hpp&gt;
#include &lt;opencv2/core.hpp&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;

//Valores escolhidos esperimentalmente
#define gH 1.7
#define gL 0.6
#define c 0.3
#define d0 7

using namespace cv;
using namespace std;

// troca os quadrantes da imagem da DFT
void deslocaDFT(Mat&amp; image ){
  Mat tmp, A, B, C, D;

  // se a imagem tiver tamanho impar, recorta a regiao para
  // evitar cópias de tamanho desigual
  image = image(Rect(0, 0, image.cols &amp; -2, image.rows &amp; -2));
  int cx = image.cols/2;
  int cy = image.rows/2;

  // reorganiza os quadrantes da transformada
  // A B   -&gt;  D C
  // C D       B A
  A = image(Rect(0, 0, cx, cy));
  B = image(Rect(cx, 0, cx, cy));
  C = image(Rect(0, cy, cx, cy));
  D = image(Rect(cx, cy, cx, cy));

  // A &lt;-&gt; D
  A.copyTo(tmp);  D.copyTo(A);  tmp.copyTo(D);

  // C &lt;-&gt; B
  C.copyTo(tmp);  B.copyTo(C);  tmp.copyTo(B);
}

int main(int argc, char** argv){
  Mat imaginaryInput, complexImage;
  Mat padded, filter, filter_print;
  Mat image, tmp;
  Mat_&lt;float&gt; zeros;
  vector&lt;Mat&gt; planos, filtros, dfts;

  int dft_M, dft_N;

  image = imread(argv[1], CV_LOAD_IMAGE_GRAYSCALE);
  imshow("filtrada", image);
  waitKey();

  // identifica os tamanhos otimos para
  // calculo do FFT
  dft_M = getOptimalDFTSize(image.rows);
  dft_N = getOptimalDFTSize(image.cols);

  // realiza o padding da imagem
  copyMakeBorder(image, padded, 0,
                 dft_M - image.rows, 0,
                 dft_N - image.cols,
                 BORDER_CONSTANT, Scalar::all(0));

  // prepara a matriz complexa e preenche com 0
  imaginaryInput = Mat(padded.size(), CV_32FC1, Scalar(0));

  //Trasforma padded em float
  padded.convertTo(padded, CV_32F);

  normalize(padded, padded, 0.0, 1.0, NORM_MINMAX);

  //Soma ambas as componentes com 1 para evitar a operação ln(0)
  cv::log(padded + 1, padded);
  cv::log(imaginaryInput + 1, imaginaryInput);

  //Concatena plano real e imaginário para realizar a DFT
  planos.push_back(padded);
  planos.push_back(imaginaryInput);

  merge(planos, complexImage);

  // Construindo a função de transferência (filtro frequencial) com o
  // mesmo tamanho e tipo da matriz complexa
  filter = Mat((dft_M &amp; -2), (dft_N &amp; -2), CV_32FC2, Scalar(0, 0));

  // Preenche o filtro homomórfico com os valores dadod pela função
  for(int i=0; i&lt; dft_M; i++){
    for(int j=0; j &lt; dft_N; j++){
      float h = (float) (gH - gL)*(1.0 - exp(-c*(pow(abs(i-dft_M/2)+abs(j-dft_N/2), 2)/pow(d0, 2)))) + gL;
      filter.at&lt;Vec2f&gt;(i, j)[0] = h;
      filter.at&lt;Vec2f&gt;(i, j)[1] = h;
    }
  }

  split(filter, filtros);
  normalize(filtros[0], filter_print, 0.0, 1.0, CV_MINMAX);
  imshow("filtro", filter_print);
  waitKey();

  // Efetua a filtragem
  dft(complexImage, complexImage);
  deslocaDFT(complexImage);
  mulSpectrums(complexImage,filter,complexImage,0);
  deslocaDFT(complexImage);
  idft(complexImage, complexImage, DFT_SCALE);

  cv::exp(complexImage,complexImage);

  planos.clear();
  split(complexImage, planos);

  // normaliza a parte real para exibicao
  normalize(planos[0], tmp, 0.0, 1.0, CV_MINMAX);
  imshow("imagem_final", tmp);
  waitKey();
  return 0;
}</code></pre>
</div>
</div>
<div id="img-aplicacaohomomorfico" class="imageblock">
<div class="content">
<img src="imagens/figura9.png" alt="Resultado">
</div>
<div class="title">Figure 10. Comparação entre uma imagem antes e depois da aplicação do filtro homomórfico.</div>
</div>
<div class="paragraph">
<p>Após a aplicação do filtro, percebemos que o brilho da imagem está mais equilibrado.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_detecção_de_bordas_com_o_algoritmo_de_canny">7. Detecção de bordas com o algoritmo de Canny</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nessa seção, vimos a implementação do detecctor de bordas de Canny funciona e como usá-lo no <em>OpenCV</em>.</p>
</div>
<div class="sect2">
<h3 id="_exercício_cannypoints">7.1. Exercício <strong><em>cannypoints</em></strong></h3>
<div class="paragraph">
<p>Usando os programa exemplos/canny.cpp e exemplos/pontilhismo.cpp como base, implementamos um algoritmo que gera um efeito pontilhista em uma imagem fornecida usando o algoritmo de Canny para aumentar sua qualidade. Isso foi feito desenhando círculos menores (dois pixels de raio em comparação com os cinco usados na geração da imagem pontilhista inicial) em cima das posições que o algoritmo indicou como borda.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;iostream&gt;
#include "opencv2/opencv.hpp"
#include &lt;algorithm&gt;
#include &lt;vector&gt;
#include &lt;ctime&gt;
#include &lt;numeric&gt;

using namespace std;
using namespace cv;

#define STEP 4
#define JITTER 3
#define RAIO 5
#define RAIO_PEQUENO 2

int main(int argc, char **argv)
{
  int width, height, limite_inferior = 80;
  int x, y;
  vector&lt;int&gt; xrange, yrange;
  vector&lt;Vec6i&gt; pontos;
  Mat points, image, border, image_bw;
  Vec3b gray;

  image = imread(argv[1], CV_LOAD_IMAGE_COLOR);

  cvtColor(image, image_bw, CV_BGR2GRAY);

  width = image.size().width;
  height = image.size().height;

  //Aplica o algoritmo de canny na imagem
  Canny(image_bw, border, limite_inferior, 3 * limite_inferior);
  imshow("bordas_canny", border);
  waitKey();

  //Obtem imagem pontilhista
  xrange.resize(height / STEP);
  yrange.resize(width / STEP);

  iota(xrange.begin(), xrange.end(), 0);
  iota(yrange.begin(), yrange.end(), 0);

  //Realiza amostragem dos pontos
  for (uint i = 0; i &lt; xrange.size(); i++)
  {
    xrange[i] = xrange[i] * STEP + STEP / 2;
  }

  for (uint i = 0; i &lt; yrange.size(); i++)
  {
    yrange[i] = yrange[i] * STEP + STEP / 2;
  }

  points = Mat(height, width, CV_8UC3, Scalar(255, 255, 255));

  random_shuffle(xrange.begin(), xrange.end());

  for (auto i : xrange)
  {
    random_shuffle(yrange.begin(), yrange.end());
    for (auto j : yrange)
    {
      x = i + rand() % (2 * JITTER) - JITTER + 1;
      y = j + rand() % (2 * JITTER) - JITTER + 1;

      //Impede o algoritmo de pegar pontos além dos limites da imagem
      if (x &gt;= height)
      {
        x = height - 1;
      }
      if (y &gt;= width)
      {
        y = width - 1;
      }

      gray = image.at&lt;Vec3b&gt;(x, y);
      circle(points,
             cv::Point(y, x),
             RAIO,
             Scalar(gray[0], gray[1], gray[2]),
             -1,
             CV_AA);
    }
  }

  imshow("imagem_pontilhista", points);
  waitKey();

  //Percorre matriz em busca da borda gerada pelo algoritmo de canny para
  //desenhar pontos pequenos
  for (int i = 0; i &lt; height; i++)
  {
    for (int j = 0; j &lt; width; j++)
    {
      if (border.at&lt;uchar&gt;(i, j) != 0)
      {
        //Armazena a cor origina do ponto, bem como sua posição na
        //estrutura Vec6i, que armazena 6 inteiros
        gray = image.at&lt;Vec3b&gt;(i, j);
        pontos.push_back(Vec6i(j, i, gray[0], gray[1], gray[2], 0));
      }
    }
  }

  random_shuffle(pontos.begin(), pontos.end());

  //Desenha pontos pequenos na imagem
  Scalar cor;
  for (int i = 0; i &lt; pontos.size(); i++)
  {
    Point p(pontos.at(i)[0], pontos.at(i)[1]);
    cor = Scalar(pontos.at(i)[2], pontos.at(i)[3], pontos.at(i)[4]);
    circle(points,
           p,
           RAIO_PEQUENO,
           cor,
           -1,
           CV_AA);
  }

  imshow("imagem_pontilhista_corrigida", points);
  waitKey();

  imwrite("cannyborders.png", points);
  return 0;
}</code></pre>
</div>
</div>
<div id="img-pontilhismomelhor" class="imageblock">
<div class="content">
<img src="imagens/figura10.png" alt="Resultado">
</div>
<div class="title">Figure 11. Imagem pontilhista antes e depois do processo de melhora na qualidade.</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_quantização_vetorial_com_k_means">8. Quantização vetorial com <em>k-means</em></h2>
<div class="sectionbody">
<div class="paragraph">
<p>Nessa seção, aprendemos sobre o funcionamento desse algoritmo de agrupamento e sua utilização no <em>OpenCV</em></p>
</div>
<div class="sect2">
<h3 id="_exercício_kmeans">8.1. Exercício <strong><em>kmeans</em></strong></h3>
<div class="paragraph">
<p>Com base no programa kmeans.cpp, fizemos um programa que executa <code>nRodadas</code> vezes o algoritmo <em>k-means</em> em uma imagem iniciando os centros de forma aleatória.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp">#include &lt;opencv2/opencv.hpp&gt;
#include &lt;cstdlib&gt;
#include &lt;vector&gt;
#include &lt;iostream&gt;
#include &lt;GraphicsMagick/Magick++.h&gt; //Biblioteca responsável pela geração do GIF

using namespace std;
using namespace cv;

int main( int argc, char** argv ){
  Magick::InitializeMagick(NULL);
  int nClusters = 6;
  Mat rotulos;
  int nRodadas = 1;
  int nExecucoes = 10;
  Mat centros;

  if(argc!=3){
	  exit(0);
  }

  //Efetua leitura da imagem
  Mat img = imread( argv[1], CV_LOAD_IMAGE_COLOR);
  Mat samples(img.rows * img.cols, 3, CV_32F);

  //Insere cada pixel da matriz da imagem em um vetor
  for( int y = 0; y &lt; img.rows; y++ ){
    for( int x = 0; x &lt; img.cols; x++ ){
      for( int z = 0; z &lt; 3; z++){
        samples.at&lt;float&gt;(y + x*img.rows, z) = img.at&lt;Vec3b&gt;(y,x)[z];
	    }
	  }
  }

  //Executa o kmeans nExecucoes vezes, inserindo-os no vetor rotulada
  vector&lt;Mat&gt; rotulada(nExecucoes,  Mat(img.size(), img.type()) );
  vector&lt;Magick::Image&gt; criarGif;
  for(int i = 0; i&lt;nExecucoes; i++){
    kmeans(samples,
          nClusters,
          rotulos,
          TermCriteria(CV_TERMCRIT_ITER|CV_TERMCRIT_EPS, 10000, 0.0001),
          nRodadas,
          KMEANS_RANDOM_CENTERS,
          centros );

    for( int y = 0; y &lt; img.rows; y++ ){
      for( int x = 0; x &lt; img.cols; x++ ){
        int indice = rotulos.at&lt;int&gt;(y + x*img.rows,0);
        rotulada.at(i).at&lt;Vec3b&gt;(y,x)[0] = (uchar) centros.at&lt;float&gt;(indice, 0);
        rotulada.at(i).at&lt;Vec3b&gt;(y,x)[1] = (uchar) centros.at&lt;float&gt;(indice, 1);
        rotulada.at(i).at&lt;Vec3b&gt;(y,x)[2] = (uchar) centros.at&lt;float&gt;(indice, 2);
      }
    }

    imshow( "Imagem Clusterizada", rotulada.at(i) );
    waitKey(50);

    //Converte a imagem de cv:Mat para Magick::Image, definindo que cada quadro
    //da animação terá duração de 500ms
    criarGif.push_back(Magick::Image(img.cols,
                                      img.rows,
                                      "BGR",
                                      Magick::StorageType::CharPixel,
                                      (char *)rotulada.at(i).data));
    criarGif.back().animationDelay(50);
  }

  //Gera o gif, colocando-o no arquivo "saidaKmeans.gif"
  Magick::writeImages(criarGif.begin(), criarGif.end(), "saidaKmeans.gif");
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>No fim é gerado um GIF animado para compararmos os resultados de cada iteração. Isso foi possivel por meio da instalação do <em>GraphicMagick</em> por meio da linha de comando abaixo e da modificação do arquivo <a href="programs/Makefile">Makefile</a> para que código pudesse ser compilado.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="bash">$ sudo apt install libgraphicsmagick++1-dev</code></pre>
</div>
</div>
<div id="img-saidakmeans" class="imageblock">
<div class="content">
<img src="imagens/figura11.gif" alt="Resultado">
</div>
<div class="title">Figure 12. Saída das <code>nRodadas</code> do kmeans.</div>
</div>
<div class="paragraph">
<p>Como os centros dos agrupamentos são escolhidos de forma aleatória, esses pontos mudam a cada rodada, o que pode gerar imagens diferentes, conforme vemos no GIF acima.</p>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-01-11 01:36:47 -0300
</div>
</div>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },
  TeX: { equationNumbers: { autoNumber: "none" } }
})
MathJax.Hub.Register.StartupHook("AsciiMath Jax Ready", function () {
  MathJax.InputJax.AsciiMath.postfilterHooks.Add(function (data, node) {
    if ((node = data.script.parentNode) && (node = node.parentNode) && node.classList.contains("stemblock")) {
      data.math.root.display = "block"
    }
    return data
  })
})
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
</body>
</html>